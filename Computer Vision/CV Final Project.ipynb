{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the libraries**"
      ],
      "metadata": {
        "id": "crH_6zhsQ1pQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6rLdM_YCp3n"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv \n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from skimage.metrics import structural_similarity\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selecting the source folders**"
      ],
      "metadata": {
        "id": "hHJK_MODQklW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Change the directory paths as needed before running\n",
        "*   \"directory\" is the folder containing the test data (Example: evaluation/fake_test)\n",
        "*   \"resource_folder\" is the folder containing the masks and other resources necessary for running the code (\"Vasile_Andrei_408/resources\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gCoveEvqx8Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data source directory\n",
        "directory = '/content/drive/MyDrive/Assignment/test'\n",
        "\n",
        "# The folder containing the masks used\n",
        "resource_folder = \"/content/drive/MyDrive/Assignment\""
      ],
      "metadata": {
        "id": "4sus10NYQtHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzmxytYEVX0"
      },
      "source": [
        "# **Task 1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target dartboard analysis\n",
        "\n",
        "Obtain the number of darts and their locations (ex: 2,6,7)\n",
        "\n",
        "(Dataset contains maximum 3 darts in a single image)"
      ],
      "metadata": {
        "id": "k9XtIpd3NEts"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4G6XnKrGSbu"
      },
      "outputs": [],
      "source": [
        "# The template dartboard used as a model for aligning the other photos\n",
        "model = (np.array(cv.imread(resource_folder + '/template_task1.jpg', flags = cv.IMREAD_GRAYSCALE)))\n",
        "# The score mask used for determining the region the dart landed on\n",
        "score_mask = (np.array(cv.imread(resource_folder + '/task 1 score mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "# A mask of the exterior of the dart board used to remove the edges of the image where no darts could land\n",
        "outer_mask = (np.array(cv.imread(resource_folder + '/task 1 outer mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "\n",
        "directory_task1 = directory + '/Task1'\n",
        " \n",
        "\n",
        "# Iterate over the files in directory\n",
        "for filename in sorted(os.listdir(directory_task1)):\n",
        "\tpath = os.path.join(directory_task1, filename)\n",
        "\tif os.path.isfile(path):\n",
        "\t\ttarget_image = (np.array(cv.imread(path, flags = cv.IMREAD_GRAYSCALE)))\n",
        "\n",
        "\t\t# Thresholding using Otsu's method\n",
        "\t\tret,target_image_thresh = cv.threshold(target_image,127,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
        "\t\tret,model_thresh = cv.threshold(model,127,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
        "\n",
        "\t\t# Applying Gaussian blur\n",
        "\t\tkernel_size = 5\n",
        "\t\ttarget_image_thresh = cv.GaussianBlur(target_image_thresh,(kernel_size, kernel_size),0)\n",
        "\t\tmodel_thresh = cv.GaussianBlur(model_thresh,(kernel_size, kernel_size),0)\n",
        "\n",
        "\t\t# Finding the keypoints in both images using ORB\n",
        "\t\torb = cv.ORB_create(5000)\n",
        "\t\t(keypoints1, descriptors1) = orb.detectAndCompute(target_image_thresh, None)\n",
        "\t\t(keypoints2, descriptors2) = orb.detectAndCompute(model_thresh, None)\n",
        "\n",
        "\t\t# Matching the features\n",
        "\t\tmethod = cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
        "\t\tmatcher = cv.DescriptorMatcher_create(method)\n",
        "\t\tmatches = matcher.match(descriptors1, descriptors2, None)\n",
        "\n",
        "\t\tmatches = sorted(matches, key=lambda x:x.distance)\n",
        "\n",
        "\t\t# Keep only the top 10% of matches to reduce noise\n",
        "\t\tkeep = int(len(matches) * 0.1)\n",
        "\t\tmatches = matches[:keep]\n",
        "\n",
        "\n",
        "\t\t# Matching the keypoints in the image to the keypoints in the model\n",
        "\t\tpoints1 = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\t\tpoints2 = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\t\t\n",
        "\t\tfor (i, m) in enumerate(matches):\n",
        "\t\t\t\tpoints1[i] = keypoints1[m.queryIdx].pt\n",
        "\t\t\t\tpoints2[i] = keypoints2[m.trainIdx].pt\n",
        "\n",
        "\n",
        "\t\t# Finding the homography\n",
        "\t\tmatrix, mask = cv.findHomography(points1, points2, method=cv.RANSAC)\n",
        "\n",
        "\t\t(h, w) = model.shape[:2]\n",
        "\n",
        "\t\t# Aligning the images\n",
        "\t\tresult = cv.warpPerspective(target_image, matrix, (w, h))\n",
        "\n",
        "\n",
        "\t\tresult_copy = result.copy()\n",
        "\t\tmodel_copy = model.copy()\n",
        "\n",
        "\t\tresult_copy = cv.GaussianBlur(result_copy,(25, 25),0)\n",
        "\t\tmodel_copy = cv.GaussianBlur(model_copy,(25, 25),0)\n",
        "\n",
        "\n",
        "\t\t# Now that the images are aligned finding the differences between them will give us an image of the darts\n",
        "\t\t(score, diff) = structural_similarity(result_copy, model_copy, full=True)\n",
        "\t\tdiff = (diff * 255).astype(\"uint8\")\n",
        "\n",
        "\t\tthresh = cv.threshold(diff, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
        "\n",
        "\t\t# The kernels used for dilating, opening and closing transformations\n",
        "\t\tkernel = cv.getStructuringElement(cv.MORPH_RECT, (10,1))\n",
        "\t\tkernel1 = cv.getStructuringElement(cv.MORPH_RECT, (5,5))\n",
        "\t\tkernel2 = cv.getStructuringElement(cv.MORPH_RECT,(20,20))\n",
        "\n",
        "\t\tthresh_copy = thresh.copy()\n",
        "\t\tthresh_copy = cv.dilate(thresh_copy, kernel, iterations = 5)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_OPEN, kernel1)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_CLOSE, kernel2)\n",
        "\n",
        "\t\t# Removing the edges of the image to further remove noise\n",
        "\t\tthresh_copy = cv.subtract(thresh_copy, outer_mask)\n",
        "\n",
        "\t\t# Finding the countours\n",
        "\t\tcontours = cv.findContours(thresh_copy.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcontours = imutils.grab_contours(contours)\n",
        "\t\n",
        "\n",
        "\t\t# Taking the 6 biggest contours in case the darts got sectioned during the process of extracting the differences\n",
        "\t\tdarts_countours = sorted(contours, key=cv.contourArea, reverse=True)[:6]\n",
        "\n",
        "\n",
        "\t\t# Finding the darts and the position they landed on\n",
        "\t\tdarts_counter = 0\n",
        "\t\tdarts_positions = []\n",
        "\n",
        "\t\tfor dart in darts_countours:\n",
        "\t\t\tif(darts_counter == 3):\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\t# We set a minimum contour area to avoid accepting left-over noise after processing\n",
        "\t\t\tif (cv.contourArea(dart) < 5667.6):\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\t# If the dart wasn't sectioned during processing it will have a larger area\n",
        "\t\t\t# In this case we just count the dart and check the location\n",
        "\t\t\telif (cv.contourArea(dart) > 57667.6):\n",
        "\t\t\t\textLeft = tuple(dart[dart[:, :, 0].argmin()][0])\n",
        "\t\t\t\tdarts_counter = darts_counter + 1\n",
        "\t\t\t\tcv.circle(thresh_copy, extLeft, 8, (0, 0, 0), -1)\n",
        "\t\t\t\tdarts_positions.append(score_mask[extLeft[1]][extLeft[0]])\n",
        "\n",
        "\t\t\t# Otherwise we try to find the tip of the dart by checking for\n",
        "\t\t\t# shapes with much larger width than height\n",
        "\t\t\telse:\n",
        "\t\t\t\textLeft = tuple(dart[dart[:, :, 0].argmin()][0])\n",
        "\t\t\t\textRight = tuple(dart[dart[:, :, 0].argmax()][0])\n",
        "\t\t\t\textTop = tuple(dart[dart[:, :, 1].argmin()][0])\n",
        "\t\t\t\textBot = tuple(dart[dart[:, :, 1].argmax()][0])\n",
        "\n",
        "\t\t\t\twidth = abs(extLeft[0]-extRight[0])\n",
        "\t\t\t\theight = abs(extTop[1]-extBot[1])\n",
        "\n",
        "\t\t\t\tif (width > 2.4*height):\n",
        "\t\t\t\t\tdarts_counter = darts_counter + 1\n",
        "\t\t\t\t\tcv.circle(thresh_copy, extLeft, 8, (0, 0, 0), -1)\n",
        "\t\t\t\t\tdarts_positions.append(score_mask[extLeft[1]][extLeft[0]])\n",
        "\n",
        "\n",
        "\n",
        "\t\t# Writing the prediction text files\n",
        "\t\tanswer_path = resource_folder + \"/evaluation/submission_files/Vasile_Andrei_408/Task1/\" + filename\n",
        "\n",
        "\t\tanswer_txt = answer_path.replace(\".jpg\", \"_predicted.txt\")\n",
        "\t\twith open(answer_txt, 'w') as f:\n",
        "\t\t\tf.write(str(darts_counter)+\"\\n\")\n",
        "\t\t\tfor position in darts_positions:\n",
        "\t\t\t\tf.write(str(position)+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1qEkPZwKyjV"
      },
      "source": [
        "# **Task 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classic dartboard analysis\n",
        "\n",
        "Obtain the number of darts and their locations (ex: s20, b25, t19)\n",
        "\n",
        "(Dataset contains maximum 3 darts in a single image)"
      ],
      "metadata": {
        "id": "stMrVBfWN3zz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQAtCvLMK0PU"
      },
      "outputs": [],
      "source": [
        "# The template dartboard used as a model for aligning the other photos\n",
        "model = (np.array(cv.imread(resource_folder + '/template_task2.jpg', flags = cv.IMREAD_GRAYSCALE)))\n",
        "# The segment mask used for determining the region the dart landed\n",
        "segment_mask = (np.array(cv.imread(resource_folder +  '/segments mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "# The masks for the multiplier regions\n",
        "single_ring_mask = (np.array(cv.imread(resource_folder +  '/single ring mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "double_ring_mask = (np.array(cv.imread(resource_folder +  '/double ring mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "triple_ring_mask = (np.array(cv.imread(resource_folder +  '/triple ring mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "outer_b_mask = (np.array(cv.imread(resource_folder +  '/outer b mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "inner_b_mask = (np.array(cv.imread(resource_folder +  '/inner b mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "# The exterior of the dart board used to remove the edges of the image where no darts could land\n",
        "outer_mask = (np.array(cv.imread(resource_folder +  '/task 1 outer mask.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "ring = \"s\"\n",
        "\n",
        "directory_task2 = directory + '/Task2'\n",
        " \n",
        "\n",
        "# Iterate over the files in directory\n",
        "for filename in sorted(os.listdir(directory_task2)):\n",
        "\tpath = os.path.join(directory_task2, filename)\n",
        "\tif os.path.isfile(path):\n",
        "\t\ttarget_image = (np.array(cv.imread(path, flags = cv.IMREAD_GRAYSCALE)))\n",
        "\n",
        "\t\t# Thresholding using Otsu's method\n",
        "\t\tret,target_image_thresh = cv.threshold(target_image,127,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
        "\t\tret,model_thresh = cv.threshold(model,127,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
        "\n",
        "\t\t# Applying Gaussian blur\n",
        "\t\tkernel_size = 5\n",
        "\t\ttarget_image_thresh = cv.GaussianBlur(target_image_thresh,(kernel_size, kernel_size),0)\n",
        "\t\tmodel_thresh = cv.GaussianBlur(model_thresh,(kernel_size, kernel_size),0)\n",
        "\n",
        "\t\t# Finding the keypoints in both images using ORB\n",
        "\t\torb = cv.ORB_create(5000)\n",
        "\t\t(keypoints1, descriptors1) = orb.detectAndCompute(target_image_thresh, None)\n",
        "\t\t(keypoints2, descriptors2) = orb.detectAndCompute(model_thresh, None)\n",
        "\n",
        "\t\t# Matching the features\n",
        "\t\tmethod = cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
        "\t\tmatcher = cv.DescriptorMatcher_create(method)\n",
        "\t\tmatches = matcher.match(descriptors1, descriptors2, None)\n",
        "\n",
        "\t\tmatches = sorted(matches, key=lambda x:x.distance)\n",
        "\n",
        "\t\t# Keep only the top 10% of matches to reduce noise\n",
        "\t\tkeep = int(len(matches) * 0.1)\n",
        "\t\tmatches = matches[:keep]\n",
        "\n",
        "\n",
        "\t\t# Matching the keypoints in the image to the keypoints in the model\n",
        "\t\tpoints1 = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\t\tpoints2 = np.zeros((len(matches), 2), dtype=\"float\")\n",
        "\t\t\n",
        "\t\tfor (i, m) in enumerate(matches):\n",
        "\t\t\t\t# indicate that the two keypoints in the respective images\n",
        "\t\t\t\t# map to each other\n",
        "\t\t\t\tpoints1[i] = keypoints1[m.queryIdx].pt\n",
        "\t\t\t\tpoints2[i] = keypoints2[m.trainIdx].pt\n",
        "\n",
        "\t\t# Finding the homography\n",
        "\t\tmatrix, mask = cv.findHomography(points1, points2, method=cv.RANSAC)\n",
        "\n",
        "\t\t(h, w) = model.shape[:2]\n",
        "\n",
        "\t\t# Aligning the images\n",
        "\t\tresult = cv.warpPerspective(target_image, matrix, (w, h))\n",
        "\n",
        "\t\tresult_copy = result.copy()\n",
        "\t\tmodel_copy = model.copy()\n",
        "\n",
        "\t\tresult_copy = cv.GaussianBlur(result_copy,(35, 35),0)\n",
        "\t\tmodel_copy = cv.GaussianBlur(model_copy,(35, 35),0)\n",
        "\n",
        "\t\t# Now that the images are aligned finding the differences between them will give us an image of the darts\n",
        "\t\t(score, diff) = structural_similarity(result_copy, model_copy, full=True)\n",
        "\t\tdiff = (diff * 255).astype(\"uint8\")\n",
        "\n",
        "\t\tthresh = cv.threshold(diff, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
        "\n",
        "\n",
        "\t\t# The kernels used for dilating, opening and closing transformations\n",
        "\t\tkernel = cv.getStructuringElement(cv.MORPH_RECT, (10,1))\n",
        "\t\tkernel1 = cv.getStructuringElement(cv.MORPH_RECT, (5,5))\n",
        "\t\tkernel2 = cv.getStructuringElement(cv.MORPH_RECT,(20,20))\n",
        "\n",
        "\t\tthresh_copy = thresh.copy()\n",
        "\t\tthresh_copy = cv.dilate(thresh_copy, kernel, iterations = 5)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_OPEN, kernel1)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_CLOSE, kernel2)\n",
        "\n",
        "\t\t# Removing the edges of the image to further remove noise\n",
        "\t\tthresh_copy = cv.subtract(thresh_copy, outer_mask)\n",
        "\n",
        "\t\t# Finding the countours\n",
        "\t\tcontours = cv.findContours(thresh_copy.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcontours = imutils.grab_contours(contours)\n",
        "\n",
        "\n",
        "\t\t# Taking the 6 biggest contours in case the darts got sectioned during the process of extracting the differences\n",
        "\t\tdarts_countours = sorted(contours, key=cv.contourArea, reverse=True)[:6]\n",
        "\n",
        "\t\t# Finding the darts and the position they landed on\n",
        "\t\tdarts_counter = 0\n",
        "\t\tdarts_positions = []\n",
        "\n",
        "\t\tfor dart in darts_countours:\n",
        "\t\t\tif(darts_counter == 3):\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\t\t# We set a minimum contour area to avoid checking left-over noise after processing\n",
        "\t\t\tif (cv.contourArea(dart) < 3667.6):\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\t# If the dart wasn't sectioned during processing it will have a larger area\n",
        "\t\t\t# In this case we just count the dart and check the location\n",
        "\t\t\telif (cv.contourArea(dart) > 37667.6):\n",
        "\t\t\t\textLeft = tuple(dart[dart[:, :, 0].argmin()][0])\n",
        "\t\t\t\tdarts_counter = darts_counter + 1\n",
        "\t\t\t\tcv.circle(thresh_copy, extLeft, 8, (0, 0, 0), -1)\n",
        "\t\t\t\tdarts_positions.append(segment_mask[extLeft[1]][extLeft[0]])\n",
        "\n",
        "\t\t\t# Otherwise we try to find the tip of the dart by checking for\n",
        "\t\t\t# shapes with much larger width than height\n",
        "\t\t\telse:\n",
        "\t\t\t\textLeft = tuple(dart[dart[:, :, 0].argmin()][0])\n",
        "\t\t\t\textRight = tuple(dart[dart[:, :, 0].argmax()][0])\n",
        "\t\t\t\textTop = tuple(dart[dart[:, :, 1].argmin()][0])\n",
        "\t\t\t\textBot = tuple(dart[dart[:, :, 1].argmax()][0])\n",
        "\n",
        "\t\t\t\twidth = abs(extLeft[0]-extRight[0])\n",
        "\t\t\t\theight = abs(extTop[1]-extBot[1])\n",
        "\n",
        "\t\t\t\tif (width > 2.4*height):\n",
        "\t\t\t\t\tdarts_counter = darts_counter + 1\n",
        "\t\t\t\t\tcv.circle(thresh_copy, extLeft, 8, (0, 0, 0), -1)\n",
        "\t\t\t\t\tdarts_positions.append(segment_mask[extLeft[1]][extLeft[0]])\n",
        "\n",
        "\t\t\t\t\tif (double_ring_mask[extLeft[1]][extLeft[0]] < 200):\n",
        "\t\t\t\t\t  ring = \"d\"\n",
        "\t\t\t\t\telif (triple_ring_mask[extLeft[1]][extLeft[0]] < 200):\n",
        "\t\t\t\t\t  ring = \"t\"\n",
        "\t\t\t\t\telif (outer_b_mask[extLeft[1]][extLeft[0]] < 200):\n",
        "\t\t\t\t\t  ring = \"b\"\n",
        "\t\t\t\t\t  darts_positions[-1] = 25\n",
        "\t\t\t\t\telif (inner_b_mask[extLeft[1]][extLeft[0]] < 200):\n",
        "\t\t\t\t\t  ring = \"b\"\n",
        "\t\t\t\t\t  darts_positions[-1] = 50\n",
        "\n",
        "\n",
        "\n",
        "\t\t# Writing the prediction text files\n",
        "\t\tanswer_path = resource_folder + \"/evaluation/submission_files/Vasile_Andrei_408/Task2/\" + filename\n",
        "\n",
        "\t\tanswer_txt = answer_path.replace(\".jpg\", \"_predicted.txt\")\n",
        "\n",
        "\t\twith open(answer_txt, 'w') as f:\n",
        "\t\t\tf.write(str(darts_counter)+\"\\n\")\n",
        "\t\t\tfor position in darts_positions:\n",
        "\t\t\t\tf.write(ring + str(position)+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3**"
      ],
      "metadata": {
        "id": "FrBvNHxhy8t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video analysis\n",
        "\n",
        "Analysing videos where a single dart is thrown\n",
        "\n",
        "Obtain the location of the last thrown dart\n"
      ],
      "metadata": {
        "id": "df6jPgZBOK1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = (np.array(cv.imread(resource_folder + '/auxiliary_images/template_task2.jpg', flags = cv.IMREAD_GRAYSCALE)))\n",
        "score_mask = (np.array(cv.imread(resource_folder + '/task3_score3.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "\n",
        "# The score masks for each template detected\n",
        "score_mask1 = (np.array(cv.imread(resource_folder + '/task3_score1.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "score_mask2 = (np.array(cv.imread(resource_folder + '/task3_score2.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "score_mask3 = (np.array(cv.imread(resource_folder + '/task3_score3.png', flags = cv.IMREAD_GRAYSCALE)))\n",
        "\n",
        "directory_task3 = directory + '/Task3'\n",
        "\n",
        "# Iterate over the files in directory\n",
        "for filename in sorted(os.listdir(directory_task3)):\n",
        "\tpath = os.path.join(directory_task3, filename)\n",
        "\tif os.path.isfile(path):\n",
        "\t\tvidcap = cv.VideoCapture(path)\n",
        "\t\tsuccess,image = vidcap.read()\n",
        "\t\tcount = 0\n",
        "\t\timagini = []\n",
        "\t\twhile success:\n",
        "\t\t\timagini.append(image)\n",
        "\t\t\tsuccess,image = vidcap.read()\n",
        "\t\t\tcount += 1\n",
        "\n",
        "    # The dartboard templates\n",
        "\t\ttemplate1 =(np.array(cv.imread(\"/content/drive/MyDrive/Assignment 3/task3_template3.png\")))\n",
        "\t\ttemplate2 =(np.array(cv.imread(\"/content/drive/MyDrive/Assignment 3/task3_template2.png\")))\n",
        "\t\ttemplate3 =(np.array(cv.imread(\"/content/drive/MyDrive/Assignment 3/task3_template1.png\")))\n",
        "\n",
        "\t\timg_rgb = imagini[0].copy()\n",
        "\t\timg_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "\t\ttemplates = []\n",
        "\t\ttemplates.append(cv.cvtColor(template1, cv.COLOR_BGR2GRAY)) \n",
        "\t\ttemplates.append(cv.cvtColor(template2, cv.COLOR_BGR2GRAY)) \n",
        "\t\ttemplates.append(cv.cvtColor(template3, cv.COLOR_BGR2GRAY)) \n",
        "\n",
        "\t\tthreshold = 0.8\n",
        "\t\tmask_number = 1\n",
        "\n",
        "\t\tfor template in templates:\n",
        "\t\t\tw, h = template.shape[::-1]\n",
        "\t\t\tres = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)\n",
        "\t\t\tloc = np.where( res >= threshold)\n",
        "\n",
        "      # If a template match has been found select the scoring mask for it\n",
        "\t\t\tif loc[0].size == 0:\n",
        "\t\t\t\tmask_number = mask_number + 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor pt in zip(*loc[::-1]):\n",
        "\t\t\t\t\tcv.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
        "\t\t\t\tbreak\n",
        "    \n",
        "\t\tif(mask_number == 1):\n",
        "\t\t\tscore_mask = score_mask3\n",
        "\t\telif(mask_number == 2):\n",
        "\t\t\tscore_mask = score_mask2\n",
        "\t\telse:\n",
        "\t\t\tscore_mask = score_mask1\n",
        "      \n",
        "\n",
        "\t\tgrayA = cv.cvtColor(imagini[0], cv.COLOR_BGR2GRAY)\n",
        "\t\tgrayB = cv.cvtColor(imagini[-1], cv.COLOR_BGR2GRAY)\n",
        "\t\t(score, diff) = structural_similarity(grayA, grayB, full=True)\n",
        "\t\tdiff = (diff * 255).astype(\"uint8\")\n",
        "\n",
        "\t\tthresh_copy = cv.threshold(diff, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
        "\n",
        "    # The kernels used for dilating, opening and closing transformations\n",
        "\t\tkernel = cv.getStructuringElement(cv.MORPH_RECT, (5,1))\n",
        "\t\tkernel1 = cv.getStructuringElement(cv.MORPH_RECT, (5,5))\n",
        "\t\tkernel2 = cv.getStructuringElement(cv.MORPH_RECT,(15,15))\n",
        "\n",
        "\t\tthresh_copy = thresh_copy.copy()\n",
        "\t\tthresh_copy = cv.dilate(thresh_copy, kernel, iterations = 5)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_OPEN, kernel1)\n",
        "\t\tthresh_copy = cv.morphologyEx(thresh_copy, cv.MORPH_CLOSE, kernel2)\n",
        "\n",
        "\t\tcontours = cv.findContours(thresh_copy.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\t\tcontours = imutils.grab_contours(contours)\n",
        "\n",
        "\n",
        "    # Taking the biggest contour\n",
        "\t\tdart = max(contours, key=cv.contourArea)\n",
        "\n",
        "    # Finding the dart and the position it landed on\n",
        "\t\tdarts_counter = 0\n",
        "\t\tdart_position = 0\n",
        "\n",
        "\n",
        "\t\textLeft = tuple(dart[dart[:, :, 0].argmin()][0])\n",
        "\t\tdarts_counter = darts_counter + 1\n",
        "\t\tcv.circle(thresh_copy, extLeft, 8, (0, 0, 0), -1)\n",
        "\t\tdart_position = score_mask[extLeft[1]][extLeft[0]]\n",
        "\t\t\n",
        "\t\t\n",
        "    # The score masks follow the rule: \n",
        "    # single region = one and two digits pixel values (ex: 20, 5, 19)\n",
        "    # double region = 3 digits values, 1 prefix (ex: 120, 105)\n",
        "    # triple region = 3 digits values, 2 prefix\n",
        "\n",
        "    # Selecting the multiplier region and dart position\n",
        "\t\tmultiplier = dart_position \n",
        "\t\tdart_position = dart_position % 100\n",
        "\t\tdigits_number = 1\n",
        "\n",
        "\t\t# Extracting the first digit of the pixel value\n",
        "\t\twhile (multiplier >= 10):\n",
        "\t\t\tmultiplier = int(multiplier / 10)\n",
        "\t\t\tdigits_number = digits_number + 1\n",
        "\n",
        "\t\tmultiplier = multiplier + 1\n",
        "\t\t\n",
        "\t\t# Setting the letter for the multiplier\n",
        "\t\tif multiplier == 1 or digits_number < 3:\n",
        "\t\t\tletter = \"s\"\n",
        "\t\telif multiplier == 2:\n",
        "\t\t\tletter = \"d\"\n",
        "\t\telse:\n",
        "\t\t\tletter = \"t\"\n",
        "\n",
        "\t\tif dart_position == 25 or dart_position == 50:\n",
        "\t\t\tletter = \"b\"\n",
        "\n",
        "    # Writing the prediction text files\n",
        "\t\tanswer_path = resource_folder + \"/evaluation/submission_files/Vasile_Andrei_408/Task3/\" + filename\n",
        "\n",
        "\t\tanswer_txt = answer_path.replace(\".mp4\", \"_predicted.txt\")\n",
        "\n",
        "\t\twith open(answer_txt, 'w') as f:\n",
        "\t\t\tf.write(letter + str(dart_position))"
      ],
      "metadata": {
        "id": "amKMIflUO6YM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "GitHub Ver Computer Vision Assignment 3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}